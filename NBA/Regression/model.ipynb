{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('clean_data.csv')\n",
    "data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "odds_data = pd.read_csv('clean_odds.csv')\n",
    "odds_data = odds_data.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_games = set(odds_data['GAME_ID'])\n",
    "data = data[~data['GAME_ID'].isin(odds_games)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(324)\n",
    "grouped = data.groupby('GAME_ID')\n",
    "group_keys = list(grouped.groups.keys())\n",
    "np.random.shuffle(group_keys)\n",
    "shuffled_data = pd.concat([grouped.get_group(key) for key in group_keys]).reset_index(drop=True)\n",
    "n1 = int(0.8 * len(data))\n",
    "n2 = int(0.9 * len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ['OFF_RATING',\n",
    "       'OREB_PCT', 'TM_TOV_PCT', 'TS_PCT', 'USG_PCT', 'PACE_PER40',\n",
    "       'POSS', 'PIE', 'DREB', 'AST', 'STL','PTS', 'T1_OR', 'T1_AP', 'T1_UP', 'T1_PACE', 'T1_PIE',\n",
    "       'T1_TO', 'T1_PTS', 'T2_OR', 'T2_AP', 'T2_UP', 'T2_PACE', 'T2_PIE',\n",
    "       'T2_TO', 'T2_PTS', 'T3_OR', 'T3_AP', 'T3_UP', 'T3_PACE', 'T3_PIE',\n",
    "       'T3_TO', 'T3_PTS', 'T4_OR', 'T4_AP', 'T4_UP', 'T4_PACE', 'T4_PIE',\n",
    "       'T4_TO', 'T4_PTS', 'O1_MIN', 'O1_DR', 'O2_MIN', 'O2_DR', 'O3_MIN',\n",
    "       'O3_DR', 'O4_MIN', 'O4_DR', 'O5_MIN', 'O5_DR']\n",
    "\n",
    "f_means = {}\n",
    "f_sd = {}\n",
    "for stat in stats:\n",
    "    f_means[stat] = shuffled_data[:n1][stat].mean()\n",
    "    f_sd[stat] = shuffled_data[:n1][stat].std()\n",
    "\n",
    "def standardize_data(df):\n",
    "    for col in df.columns:\n",
    "        if col in f_means:\n",
    "            df[col] = (df[col] - f_means[col]) / f_sd[col]\n",
    "    return df\n",
    "\n",
    "def build_dataset(df):\n",
    "    pos_dic = {\n",
    "        'G':0,\n",
    "        'F':1,\n",
    "        'C':2\n",
    "    }\n",
    "    is_home = torch.tensor(df['HOME?'].values)\n",
    "    start_pos = torch.tensor([pos_dic.get(elem, elem) for elem in df['START_POSITION'].values])\n",
    "    hot_start_pos = F.one_hot(start_pos, num_classes=3)\n",
    "    ref1 = F.one_hot(torch.tensor(df['REF_1'].values.astype(int)), num_classes=142)\n",
    "    ref2 = F.one_hot(torch.tensor(df['REF_2'].values.astype(int)), num_classes=142)\n",
    "    ref3 = F.one_hot(torch.tensor(df['REF_3'].values.astype(int)), num_classes=142)\n",
    "    refs = ref1 + ref2 + ref3\n",
    "    X = torch.cat((is_home.view(-1, 1), hot_start_pos, refs), dim=1)\n",
    "\n",
    "    for stat in stats:\n",
    "        stat_tensor = torch.tensor(df[stat].values)\n",
    "        X = torch.cat((X, stat_tensor.view(-1, 1)), dim=1)\n",
    "    X = X.to(torch.float32)\n",
    "\n",
    "    Y = torch.tensor(df['PTS_y'].values).to(torch.float32)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "shuffled_data = standardize_data(shuffled_data)\n",
    "Xtr, Ytr = build_dataset(shuffled_data[:n1])\n",
    "Xval, Yval = build_dataset(shuffled_data[n1:n2])\n",
    "Xte, Yte = build_dataset(shuffled_data[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_features = 7\n",
    "tm_out_size = 15\n",
    "\n",
    "class TeammateModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features=tm_features, out_features=tm_out_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_out_size = 30\n",
    "\n",
    "class TeamModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tm_model = TeammateModel()\n",
    "        self.linear = nn.Linear(in_features=4*tm_out_size, out_features=t_out_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.tm_model(x.view(-1, 4, tm_features))\n",
    "        out = self.linear(x.view(-1, 4*tm_out_size))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_features = 2\n",
    "op_out_size = 3\n",
    "\n",
    "class OpponentModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features=op_features, out_features=op_out_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_out_size = 10\n",
    "\n",
    "class OppTeamModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.op_model = OpponentModel()\n",
    "        self.linear = nn.Linear(in_features=5*op_out_size, out_features=opt_out_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.op_model(x.view(-1, 5, op_features))\n",
    "        out = self.linear(x.view(-1, 5*op_out_size))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RefModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features=142, out_features=5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_features = 16\n",
    "total_features = t_out_size + opt_out_size + other_features + 5\n",
    "\n",
    "class FinalModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.t_model = TeamModel()\n",
    "        self.opt_model = OppTeamModel()\n",
    "        self.r_model = RefModel()\n",
    "        self.linear = nn.Linear(in_features=total_features, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_split = torch.split(x, split_size_or_sections=[other_features, 142, 4 * tm_features, 5 * op_features], dim=1)\n",
    "        x1 = torch.squeeze(x_split[0])\n",
    "        x2 = self.r_model(x_split[1])\n",
    "        x3 = self.t_model(x_split[2])\n",
    "        x4 = self.opt_model(x_split[3])\n",
    "        out = self.linear(torch.cat((x1, x2, x3, x4), dim=1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FinalModel()\n",
    "criterion = nn.MSELoss()\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(34.8756, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.5031, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.7223, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.1781, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.8502, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.5351, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.4756, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.3665, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.3957, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.5428, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.9169, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.6872, grad_fn=<MseLossBackward0>)\n",
      "tensor(47.9575, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.0550, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.5007, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.5758, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.7543, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.1152, grad_fn=<MseLossBackward0>)\n",
      "tensor(54.6673, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.6508, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.1826, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.7211, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.9184, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.4291, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.4264, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.1729, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.4449, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0376, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.2025, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.8078, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.1988, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.8963, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.4638, grad_fn=<MseLossBackward0>)\n",
      "tensor(50.7824, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.6930, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.3426, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6599, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.8226, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.7110, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.1506, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.8560, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.7316, grad_fn=<MseLossBackward0>)\n",
      "tensor(50.3145, grad_fn=<MseLossBackward0>)\n",
      "tensor(50.6414, grad_fn=<MseLossBackward0>)\n",
      "tensor(53.4047, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.2519, grad_fn=<MseLossBackward0>)\n",
      "tensor(48.8214, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.9815, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.0300, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.2569, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.4223, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.9900, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.6654, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.1316, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.2562, grad_fn=<MseLossBackward0>)\n",
      "tensor(62.4254, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.3380, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.5879, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.4229, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.5683, grad_fn=<MseLossBackward0>)\n",
      "tensor(52.5897, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.9935, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.3900, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.0644, grad_fn=<MseLossBackward0>)\n",
      "tensor(52.3428, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8046, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.2675, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.4319, grad_fn=<MseLossBackward0>)\n",
      "tensor(66.3231, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4356, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.5701, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.6757, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.1975, grad_fn=<MseLossBackward0>)\n",
      "tensor(53.1642, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.0757, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.9952, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.9547, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.3258, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.4490, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.3220, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.3944, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.9066, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.0594, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.5734, grad_fn=<MseLossBackward0>)\n",
      "tensor(55.2992, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.1566, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.7293, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.4102, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7409, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.9544, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.2371, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.9007, grad_fn=<MseLossBackward0>)\n",
      "tensor(54.4293, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.5502, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.2113, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.6412, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.5912, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.7590, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.3334, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.7621, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100000\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # contruct minibatch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "\n",
    "    # forward pass\n",
    "    pred = model(Xtr[ix])\n",
    "    loss = criterion(pred.view(batch_size), Ytr[ix])\n",
    "\n",
    "    # backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10000 == 0:\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(40.3648, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# find validation loss\n",
    "pred_val = model(Xval)\n",
    "loss_val = criterion(pred_val.view(Yval.shape), Yval)\n",
    "print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_odds(df):\n",
    "    pos_dic = {\n",
    "        'G':0,\n",
    "        'F':1,\n",
    "        'C':2\n",
    "    }\n",
    "    is_home = torch.tensor(df['HOME?'].values)\n",
    "    start_pos = torch.tensor([pos_dic.get(elem, elem) for elem in df['START_POSITION'].values])\n",
    "    hot_start_pos = F.one_hot(start_pos, num_classes=3)\n",
    "    ref1 = F.one_hot(torch.tensor(df['REF_1'].values.astype(int)), num_classes=142)\n",
    "    ref2 = F.one_hot(torch.tensor(df['REF_2'].values.astype(int)), num_classes=142)\n",
    "    ref3 = F.one_hot(torch.tensor(df['REF_3'].values.astype(int)), num_classes=142)\n",
    "    refs = ref1 + ref2 + ref3\n",
    "    X = torch.cat((is_home.view(-1, 1), hot_start_pos, refs), dim=1)\n",
    "\n",
    "    for stat in stats:\n",
    "        stat_tensor = torch.tensor(df[stat].values)\n",
    "        X = torch.cat((X, stat_tensor.view(-1, 1)), dim=1)\n",
    "    X = X.to(torch.float32)\n",
    "\n",
    "    pts = torch.tensor(df['PTS_y'].values).to(torch.float32)\n",
    "    ol = torch.tensor(df['O_LINE'].values).to(torch.float32)\n",
    "    oo = torch.tensor(df['O_ODDS'].values).to(torch.float32)\n",
    "    ul = torch.tensor(df['U_LINE'].values).to(torch.float32)\n",
    "    uo = torch.tensor(df['U_ODDS'].values).to(torch.float32)\n",
    "    Y = torch.stack((pts, ol, oo, ul, uo), dim=1)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine profits\n",
    "odds_data = pd.read_csv('clean_odds.csv')\n",
    "odds_data = odds_data.drop(columns=['Unnamed: 0'])\n",
    "odds_data = standardize_data(odds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'OFF_RATING'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'OFF_RATING'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[869], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Xod, Yod \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_odds\u001b[49m\u001b[43m(\u001b[49m\u001b[43modds_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[867], line 17\u001b[0m, in \u001b[0;36mbuild_odds\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     14\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((is_home\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), hot_start_pos, refs), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stat \u001b[38;5;129;01min\u001b[39;00m stats:\n\u001b[0;32m---> 17\u001b[0m     stat_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstat\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     18\u001b[0m     X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((X, stat_tensor\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'OFF_RATING'"
     ]
    }
   ],
   "source": [
    "Xod, Yod = build_odds(odds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "-1\n",
      "tensor(0.6600)\n",
      "tensor(-0.7400)\n",
      "tensor(-0.1300)\n",
      "tensor(-1.4200)\n",
      "tensor(-3.5100)\n",
      "tensor(-2.0500)\n",
      "tensor(-1.5400)\n",
      "tensor(1.8200)\n",
      "tensor(5.4500)\n",
      "tensor(5.9600)\n",
      "tensor(4.7800)\n",
      "tensor(2.7800)\n",
      "tensor(2.5600)\n",
      "tensor(4.9900)\n",
      "tensor(7.5700)\n",
      "tensor(9.9100)\n",
      "tensor(12.4100)\n",
      "tensor(12.7000)\n",
      "tensor(12.5600)\n",
      "tensor(8.5600)\n",
      "tensor(8.2100)\n",
      "tensor(8.4800)\n",
      "tensor(9.1500)\n",
      "tensor(9.5300)\n",
      "tensor(10.3900)\n",
      "tensor(11.7500)\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "profit = 0\n",
    "bets = 0\n",
    "pred_pts = model(Xod).squeeze()\n",
    "\n",
    "for i in range(pred_pts.shape[0]):\n",
    "    if pred_pts[i] > Yod[i][1] + 0:\n",
    "        bets += 1\n",
    "        profit -= 1\n",
    "        if Yod[i][0] > Yod[i][1]:\n",
    "            profit += Yod[i][2]\n",
    "    elif pred_pts[i] < Yod[i][3] - 0:\n",
    "        bets += 1\n",
    "        profit -= 1\n",
    "        if Yod[i][0] < Yod[i][3]:\n",
    "            profit += Yod[i][4]\n",
    "    if i % 10 == 0:\n",
    "        print(profit)\n",
    "print(bets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nROI w/o refs:\\n- 5.4% on 175\\n- 6.1% on 105\\n- 15.9% on 59\\n- 17.5% on 24\\n- 46.9% on 9\\n\\nROI w/ refs:\\n- 4.9% on 268\\n- 6.8% on 171\\n- 10.1% on 116\\n- 10.1% on 57\\n- 26.5% on 34\\n- 62.4% on 14\\n'"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ROI w/o refs:\n",
    "- 5.4% on 175\n",
    "- 6.1% on 105\n",
    "- 15.9% on 59\n",
    "- 17.5% on 24\n",
    "- 46.9% on 9\n",
    "\n",
    "ROI w/ refs:\n",
    "- 4.9% on 268\n",
    "- 6.8% on 171\n",
    "- 10.1% on 116\n",
    "- 10.1% on 57\n",
    "- 26.5% on 34\n",
    "- 62.4% on 14\n",
    "'''\n",
    "\n",
    "'''\n",
    "TD:\n",
    "- GAN\n",
    "    - Get probability of over and under\n",
    "- normalization layers\n",
    "- PACE? Other stats?\n",
    "- Combine the files and shit\n",
    "- Tune hyperparamters\n",
    "- Results for other stats\n",
    "- Parlays\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
